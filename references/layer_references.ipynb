{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Masking, Input, Conv2D, MaxPooling2D, Flatten, Dense, Multiply, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "# Input shape based on the court grid and assuming a single channel for simplicity\n",
    "input_shape = (n_rows, n_cols, 1)  # n_rows=94, n_cols=50, channels=1 for player positions\n",
    "\n",
    "# Model architecture\n",
    "inputs = Input(shape=input_shape)\n",
    "mask = Masking(mask_value=0)(inputs)  # Masking layer to ignore padded zeros\n",
    "# Base convolutional layers with fewer neurons\n",
    "conv1 = Conv2D(16, kernel_size=(3, 3), activation='relu')(mask)  # Reduced from 32 to 16\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(32, (3, 3), activation='relu')(pool1)  # Reduced from 64 to 32\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# Spatial attention layer remains the same\n",
    "attention_probs = Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(pool2)\n",
    "attention_mul = Multiply()([pool2, attention_probs])\n",
    "\n",
    "# Flattening and dense layers with fewer neurons\n",
    "flatten = Flatten()(attention_mul)\n",
    "dense1 = Dense(64, activation='relu')(flatten)  # Reduced from 128 to 64\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(2, activation='softmax')(dropout)  # Output layer remains the same for binary classification\n",
    "\n",
    "# Construct and compile the model\n",
    "model = Model(inputs=[inputs], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary to inspect the architecture\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
