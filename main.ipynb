{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing cnn\n",
    "\n",
    "# inputs\n",
    "- grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datasets\n",
    "player_positions = pd.read_csv('data/train_locs.csv')\n",
    "game_outcomes = pd.read_csv('data/train_pbp.csv')\n",
    "\n",
    "# Parameters\n",
    "court_length, court_width = 94, 50\n",
    "grid_size = 1  # 1 foot grid size\n",
    "n_classes = 2  # Offensive rebound or not\n",
    "\n",
    "# Convert court dimensions to a grid\n",
    "n_rows, n_cols = int(court_length / grid_size), int(court_width / grid_size)\n",
    "\n",
    "def positions_to_grid(data, n_rows, n_cols):\n",
    "    # Initialize an empty grid\n",
    "    grid = np.zeros((n_rows, n_cols, 1))  # Single channel for player positions\n",
    "    \n",
    "    # Map player positions to grid\n",
    "    for _, row in data.iterrows():\n",
    "        x, y, code = min(int(row['court_x'] // grid_size), n_rows - 1), min(int(row['court_y'] // grid_size), n_cols - 1), row['annotation_code']\n",
    "        if 'd' in code:  # Defense\n",
    "            grid[x, y, 0] = 1\n",
    "        elif 't' in code:  # Offense excluding shooter\n",
    "            grid[x, y, 0] = 2\n",
    "        elif 's' in code:  # Shooter\n",
    "            grid[x, y, 0] = 3\n",
    "    \n",
    "    return grid\n",
    "\n",
    "# Preprocess the data\n",
    "unique_ids = player_positions['id'].unique()\n",
    "X = np.array([positions_to_grid(player_positions[player_positions['id'] == uid], n_rows, n_cols) for uid in unique_ids])\n",
    "\n",
    "# Prepare labels\n",
    "y = game_outcomes.set_index('id').loc[unique_ids]['is_oreb'].values\n",
    "y = to_categorical(y, num_classes=n_classes)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 94, 50, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 92, 48, 16)           160       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 46, 24, 16)           0         ['conv2d_9[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 44, 22, 32)           4640      ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 22, 11, 32)           0         ['conv2d_10[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 22, 11, 1)            33        ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 22, 11, 32)           0         ['max_pooling2d_7[0][0]',     \n",
      "                                                                     'conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 7744)                 0         ['multiply_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 64)                   495680    ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 64)                   0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 2)                    130       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 500643 (1.91 MB)\n",
      "Trainable params: 500643 (1.91 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Multiply, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Input shape based on the court grid and assuming a single channel for simplicity\n",
    "input_shape = (n_rows, n_cols, 1)  # n_rows=94, n_cols=50, channels=1 for player positions\n",
    "\n",
    "# Model architecture\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Base convolutional layers with fewer neurons\n",
    "conv1 = Conv2D(16, kernel_size=(3, 3), activation='relu')(inputs)  # Reduced from 32 to 16\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(32, (3, 3), activation='relu')(pool1)  # Reduced from 64 to 32\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "# Spatial attention layer remains the same\n",
    "attention_probs = Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(pool2)\n",
    "attention_mul = Multiply()([pool2, attention_probs])\n",
    "\n",
    "# Flattening and dense layers with fewer neurons\n",
    "flatten = Flatten()(attention_mul)\n",
    "dense1 = Dense(64, activation='relu')(flatten)  # Reduced from 128 to 64\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(2, activation='softmax')(dropout)  # Output layer remains the same for binary classification\n",
    "\n",
    "# Construct and compile the model\n",
    "model = Model(inputs=[inputs], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary to inspect the architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "771/771 [==============================] - 9s 10ms/step - loss: 0.5937 - accuracy: 0.7177 - val_loss: 0.5930 - val_accuracy: 0.7174\n",
      "Epoch 2/10\n",
      "771/771 [==============================] - 8s 10ms/step - loss: 0.5862 - accuracy: 0.7182 - val_loss: 0.5906 - val_accuracy: 0.7174\n",
      "Epoch 3/10\n",
      "771/771 [==============================] - 8s 10ms/step - loss: 0.5818 - accuracy: 0.7184 - val_loss: 0.5936 - val_accuracy: 0.7174\n",
      "Epoch 4/10\n",
      "771/771 [==============================] - 8s 11ms/step - loss: 0.5744 - accuracy: 0.7186 - val_loss: 0.5923 - val_accuracy: 0.7176\n",
      "Epoch 5/10\n",
      "771/771 [==============================] - 9s 12ms/step - loss: 0.5659 - accuracy: 0.7222 - val_loss: 0.5961 - val_accuracy: 0.7156\n",
      "Epoch 6/10\n",
      "771/771 [==============================] - 8s 11ms/step - loss: 0.5499 - accuracy: 0.7318 - val_loss: 0.6024 - val_accuracy: 0.7153\n",
      "Epoch 7/10\n",
      "771/771 [==============================] - 9s 12ms/step - loss: 0.5313 - accuracy: 0.7447 - val_loss: 0.6148 - val_accuracy: 0.7038\n",
      "Epoch 8/10\n",
      "771/771 [==============================] - 9s 12ms/step - loss: 0.5025 - accuracy: 0.7628 - val_loss: 0.6412 - val_accuracy: 0.6958\n",
      "Epoch 9/10\n",
      "771/771 [==============================] - 9s 11ms/step - loss: 0.4667 - accuracy: 0.7843 - val_loss: 0.6541 - val_accuracy: 0.6895\n",
      "Epoch 10/10\n",
      "771/771 [==============================] - 9s 11ms/step - loss: 0.4345 - accuracy: 0.7978 - val_loss: 0.6855 - val_accuracy: 0.6853\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,  # Adjust based on convergence and computational resources\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
